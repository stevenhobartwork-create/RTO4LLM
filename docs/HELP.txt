
╔══════════════════════════════════════════════════════════════════════════════╗
║                 REVERSIBLE TEXT OPTIMIZER v1.5.0 (C++)                       ║
║                         Build: 2025-11-26                                    ║
╚══════════════════════════════════════════════════════════════════════════════╝

PURPOSE
    Compress text files for LLM context windows while preserving 100% 
    reversibility. Reduces token count to fit more content in AI prompts.

    ┌─────────────────────────────────────────────────────────────────────────┐
    │  TESTED: LLMs successfully reconstruct original files in 100% of        │
    │  tests. The dictionary format is designed for LLM parsing.              │
    └─────────────────────────────────────────────────────────────────────────┘

USAGE
    cat file.py | rto --compress --ext py > file.rto
    cat file.rto | rto --expand > file_restored.py

    # Quick test (roundtrip)
    cat file.py | rto --compress --ext py | rto --expand | diff - file.py

OPTIONS
    --compress          Compress input text
    --expand            Expand compressed text
    --ext EXT           File extension for type-specific dict (py, js, c, etc.)
    --min-len N         Minimum word length for local dict (default: 4)
    --top-n N           Max words in local dictionary (default: 200)
    --benchmark         Run internal benchmark
    --show-global-dict  Print global dictionary
    --show-type-dict E  Print type dict for extension E
    --version           Print version
    --help              Print this help

PERFORMANCE (benchmarked on 19,985 real project files)
    ┌──────────────────────────────────────────────────────────────────────┐
    │  TOTAL: 291.5 MB tested → 256.9 MB compressed = 34.6 MB saved (11.9% avg)│
    └──────────────────────────────────────────────────────────────────────┘
    
    BY FILE SIZE:
      <1KB:        -2.4%  (skip - header overhead exceeds gains)
      1-10KB:      +7.1%  savings
      10-50KB:    +10.6%  savings
      50-100KB:   +13.3%  savings
      100-500KB:  +12.5%  savings
      500KB-1MB:  +16.2%  savings ← SWEET SPOT
      1MB+:       +15.0%  savings
    
    THROUGHPUT (12th Gen Intel i5 laptop):
      C++ (rto binary):           ~3.3 MB/s (228 files/s)
      Python (reversible_text.py): ~0.8 MB/s
    
    LLM CONTEXT WINDOW IMPACT:
      Claude (200K tokens ~ 800KB):  +95KB more code per context
      GPT-4  (128K tokens ~ 500KB):  +60KB more code per context
      Gemini (1M tokens ~ 4MB):     +476KB more code per context
      Per 10MB source code:  save ~1.19 MB
      Per 100MB codebase:    save ~11.9 MB

    The compressed format includes a JSON header:
    
    {"v":"1.2","m":{"~0":"word1","~1":"word2",...},"ext":"py"}
    
    Three dictionary tiers:
    
    ~^N  = Global dictionary (common programming keywords)
          These 88 words are built into the tool - LLM has same dict
          
    ~*N  = Type-specific dictionary (based on file extension)
          Python, JavaScript, C keywords - also built-in
          
    ~N   = Local dictionary (file-specific frequent words)
          Listed in the JSON header "m" field
    
    LLMs reconstruct by:
    1. Parsing the JSON header for local dictionary
    2. Using built-in global/type dicts (or asking for them with --show-global-dict)
    3. Replacing tokens with original words
    4. Unescaping ~~ back to ~

LLM INTEGRATION
    Send compressed file to LLM with prompt:
    
    "This is a compressed file. The header contains a local dictionary.
     Global tokens (~^N) use standard programming keywords.
     Type tokens (~*N) are language-specific.
     Expand and analyze the code."
    
    Or ask LLM to run: rto --expand < compressed.rto

TESTING METHODOLOGY
    - 10,000+ text files tested from ~/Projects
    - Every compression verified with roundtrip expand
    - Multiple LLMs tested (GPT-4, Claude, Gemini)
    - All achieved 100% reconstruction accuracy
    - Binary files auto-detected and skipped

EXAMPLES
    # Compress Python file
    cat script.py | rto --compress --ext py > script.rto

    # Compress multiple files for LLM context
    for f in *.py; do rto --compress --ext py < "$f"; done > context.rto

    # Verify roundtrip
    rto --compress --ext py < file.py | rto --expand > /tmp/test.py
    diff file.py /tmp/test.py  # Should be empty

    # View what words map to tokens
    rto --show-global-dict
    rto --show-type-dict py


